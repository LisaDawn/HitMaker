{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sqlite3\n",
      "from pandas.io import sql\n",
      "import sys\n",
      "from sklearn.externals import joblib\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Connect to Billboard, Million Song and MusixMatch tables\n",
      "conn_all = sqlite3.connect('datasets/all_the_data.db')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "popular_df = pd.io.sql.read_frame(\n",
      "                                 '''select * from pop_lyric''', \n",
      "                                 conn_all, index_col=None, coerce_float=True, params=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unpopular_df = pd.io.sql.read_frame(\n",
      "                                '''select * from unpop_lyric''', \n",
      "#'''select * from unpop_lyric2''', \n",
      "#'''select * from unpop_lyric3''', \n",
      "                                 conn_all, index_col=None, coerce_float=True, params=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# close connection\n",
      "conn_all.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pivot the popular/ unpopular\n",
      "popular_df = popular_df.pivot(index='track_id', columns='word', values='count')\n",
      "unpopular_df = unpopular_df.pivot(index='track_id', columns='word', values='count')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#replace NaNs in popular dataframe\n",
      "popular_df=popular_df.fillna(0)\n",
      "unpopular_df=unpopular_df.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#checking for completely empty columns\n",
      "#popular_df.columns[(popular_df == 0).all()]\n",
      "#unpopular_df.columns[(unpopular_df == 0).all()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert labels for popularity/unpopularity\n",
      "popular_df['!popular']=np.ones(5242)\n",
      "unpopular_df['`!popular']=np.zeros(5242)\n",
      "#unpopular_df['`!popular']=np.zeros(15726)\n",
      "#unpopular_df['`!popular']=np.zeros(26210)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# merge the two datasets together\n",
      "merged_df = pd.concat([popular_df, unpopular_df])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#replace NaNs in dataframe - because the top5 has 300 fewer columns than bottom5\n",
      "merged_df=merged_df.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unpopular_df.iloc[0:2,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Index: 2 entries, TRAAEJV128F423CF04 to TRAAEOT128F14681B9\n",
        "Columns: 4999 entries, &amp; to `!popular\n",
        "dtypes: float64(4999)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 2 entries, TRAAEJV128F423CF04 to TRAAEOT128F14681B9\n",
        "Columns: 4999 entries, & to `!popular\n",
        "dtypes: float64(4999)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PICKLE dataframe for parsing\n",
      "#popular_df.to_pickle('popular.pkl')\n",
      "unpopular_df.iloc[0:2,:].to_pickle('unpopular.pkl')\n",
      "#merged_df.to_pickle('merged.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The merged data frame is basis for feature_df\n",
      "new_feature=merged_df.ix[:,2:5001].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The merged data frame is basis for label_df\n",
      "label = merged_df.ix[:,0:1].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The label needs to be flattened from an array\n",
      "flat_label=label.flatten()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create dataframes from label/ceature numpy arrays\n",
      "\n",
      "label_df=pd.DataFrame(flat_label, index=merged_df.index, columns=[merged_df.columns[0]])\n",
      "feature_df=pd.DataFrame(new_feature, index=merged_df.index, columns=[merged_df.columns[1:5000]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert dataframe to numpy array\n",
      "feature_matrix=feature_df.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create train/test sets from pseudo-random generation\n",
      "# from http://stackoverflow.com/questions/17260109/sample-two-pandas-dataframes-the-same-way\n",
      "\n",
      "import random\n",
      "np.random.seed(1300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_source = label_df\n",
      "df_source2 = feature_df\n",
      "rows = np.random.binomial(1, .70, size=len(df_source)).astype('bool')\n",
      "\n",
      "label_train = df_source[rows]\n",
      "label_test = df_source[~rows]\n",
      "feat_train = df_source2[rows]\n",
      "feat_test = df_source2[~rows]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#label_train.T\n",
      "label_train_flat=label_train.values.flatten()\n",
      "label_test_flat=label_test.values.flatten()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "clf_nb = MultinomialNB()\n",
      "clf_nb.fit(feat_train, label_train_flat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joblib.dump(clf_nb,'nb_model.pkl') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "['nb_model.pkl',\n",
        " 'nb_model.pkl_01.npy',\n",
        " 'nb_model.pkl_02.npy',\n",
        " 'nb_model.pkl_03.npy',\n",
        " 'nb_model.pkl_04.npy',\n",
        " 'nb_model.pkl_05.npy']"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MAKE PICKLE FOR EXPORT TO PRODUCT LATER\n",
      "#import pickle\n",
      "#nb_model = pickle.dumps(clf)\n",
      "clf_nb.score(feat_test, label_test_flat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "0.67959313413858868"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_nb.score(feat_train, label_train_flat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.7128645407467975"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#nb_cpt=clf_nb.feature_log_prob_\n",
      "#nb_cpt\n",
      "clf_nb.predict_proba(feat_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([[  1.70883755e-21,   1.00000000e+00],\n",
        "       [  1.22000646e-14,   1.00000000e+00],\n",
        "       [  2.10834797e-21,   1.00000000e+00],\n",
        "       ..., \n",
        "       [  1.00000000e+00,   1.25715699e-36],\n",
        "       [  8.87671417e-10,   9.99999999e-01],\n",
        "       [  1.45049512e-09,   9.99999999e-01]])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#mean_tf=np.mean([66.94, 66.54, 66.18, 65.77, 66.97, 68.54, 65.18, 66.49, 65.81, 66.72])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#mean_notf=np.mean([68.19, 68.78, 67.3, 67.5, 68.24, 69.85, 66.35, 67.28, 67.3, 67.96])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "from time import time\n",
      "from sklearn.feature_extraction import text\n",
      "from sklearn import decomposition\n",
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples = 10000\n",
      "n_features = 5000\n",
      "n_topics=10\n",
      "n_top_words = 20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fit the NMF model\n",
      "print(\"Fitting the NMF model on with n_samples=%d and n_features=%d...\"\n",
      "      % (n_samples, n_features))\n",
      "nmf = decomposition.NMF(n_components=n_topics).fit(feat_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting the NMF model on with n_samples=10000 and n_features=5000...\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get feature names\n",
      "feature_names = merged_df.columns\n",
      "#feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topic_idx, topic in enumerate(nmf.components_):\n",
      "    print(\"Topic #%d:\" % topic_idx)\n",
      "    print(\" \".join([feature_names[i]\n",
      "                    for i in topic.argsort()[:20]]))\n",
      "    print()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic #0:\n",
        "llevar often og ogni oh ohhh ohn ohoh oi oil okay old older ole olen olhar olho oli olla olvid\n",
        "\n",
        "Topic #1:\n",
        "llevar pasion pasar fed feed pasado feelin paso feet pas partner partir fellow part femm pasa fenc passa passer peau\n",
        "\n",
        "Topic #2:\n",
        "!popular pale pan pane pant papa papel paper par para parad paradis paralyz paranoia parar palac parasit pardon pare parec\n",
        "\n",
        "Topic #3:\n",
        "llevar leg legal legend stack lei lejo lend lento stab sta lesson left let letter letzt leur leva leve level\n",
        "\n",
        "Topic #4:\n",
        "!popular ni nice nicht niemal nient niet niggaz nightmar ningu\u00e9m ni\u00f1o nobodi noi noir nois nom nome none noon nor\n",
        "\n",
        "Topic #5:\n",
        "\u00f4 practic pray domin preach dolor dollar prend doi prendr pretend prevail priest dizzi princ diz prison problem problema process\n",
        "\n",
        "Topic #6:\n",
        "!popular on one onli oo oooh oooo ooooh open oper opinion opportun opposit oppress om or orang order ordinari organ\n",
        "\n",
        "Topic #7:\n",
        "llevar monkey more morena morn mornin mortal motherfuck motion mountain mouth mua much mucha mucho mud muer muero muert muerto\n",
        "\n",
        "Topic #8:\n",
        "llevar noir nois noit nom nombr non nooit noon noos normal north nos nog nose nosso nothin notic notion notr\n",
        "\n",
        "Topic #9:\n",
        "!popular par para parad paradis paralyz paranoia parar parc pardon pare parec pari park parol paper part partner pas pasa\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nmf.components_[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([ 0.00214473,  0.        ,  0.0043051 , ...,  0.        ,\n",
        "        0.        ,  0.        ])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "pandas.core.index.Index"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nmf.components_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "(10, 4999)"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "component=sorted(zip(nmf.components_[topic_idx], merged_df.columns))\n",
      "component.reverse()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_topic = []\n",
      "for topic_idx in range(len(nmf.components_)):\n",
      "    sorted_topic.append(sorted(zip(nmf.components_[topic_idx], merged_df.columns)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_list=[]\n",
      "for idx in range(len(sorted_topic)-1):\n",
      "    sorted_list.append(sorted_topic[idx][-20:-1])\n",
      "sorted_list[6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[(0.51328896738672536, u'ceux'),\n",
        " (0.52347967099697723, u'ni\\xf1a'),\n",
        " (0.54447843232067561, u'comin'),\n",
        " (0.55699399691702189, u'9'),\n",
        " (0.5738566014838018, u'knockin'),\n",
        " (0.59000146851903712, u'wet'),\n",
        " (0.60420345396727226, u'battl'),\n",
        " (0.65124157193199328, u'wax'),\n",
        " (0.6668962161112002, u'aqu\\xed'),\n",
        " (0.67632942866469004, u'giorno'),\n",
        " (0.68463466189760991, u'gon'),\n",
        " (0.70000016698660794, u'mutta'),\n",
        " (0.70914067018760618, u'ira'),\n",
        " (0.80192549851888117, u'shatter'),\n",
        " (0.81924114033179085, u'ba'),\n",
        " (1.1652657895743597, u'onto'),\n",
        " (1.2572911460266829, u'loud'),\n",
        " (1.3953033151386938, u'odio'),\n",
        " (2.2433717128986772, u'ye')]"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(sorted_topic[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "h\u00f6r\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.preprocessing import scale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(42)\n",
      "n_samples, n_features = merged_df.shape\n",
      "# get feature names\n",
      "feature_names = merged_df.columns\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "kmeans = KMeans(n_clusters=n_topics).fit(feat_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm\n",
      "clf_svm = svm.SVC()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_svm.fit(feat_train, label_train_flat) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_svm.predict(feat_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([ 1.,  1.,  1., ...,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_svm.score(feat_test, label_test_flat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "0.70089001907183723"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf_rf = RandomForestClassifier(n_estimators=10)\n",
      "clf_rf = clf_rf.fit(feat_train, label_train_flat) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "clf_ab = AdaBoostClassifier(n_estimators=100)\n",
      "scores = cross_val_score(clf_ab, feat_train, feat_test)\n",
      "scores.mean() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Found array with dim 3146. Expected 7338",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-47-b4b0293643fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf_ab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_ab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, score_func, pre_dispatch)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[0mArray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mscores\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcross\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \"\"\"\n\u001b[1;32m-> 1132\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_lists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m     scorer = _deprecate_loss_and_score_funcs(\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise ValueError(\"Found array with dim %d. Expected %d\"\n\u001b[1;32m--> 211\u001b[1;33m                              % (size, n_samples))\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_lists\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Found array with dim 3146. Expected 7338"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}